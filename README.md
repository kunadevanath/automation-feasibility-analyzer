# ğŸ§ª Automation Feasibility Analyzer

This **Streamlit dashboard** evaluates the feasibility of automating test cases using a **local LLM via Ollama**. It loads test cases from an Excel file, runs classification, and displays results in a **branded, judge-ready UI**.


---

## ğŸš€ Setup Instructions

### 1. ğŸ“¦ Install Python 3.12

Download and install Python 3.12 from the official Python website:  
ğŸ‘‰ [https://www.python.org/downloads/release/python-3120/](https://www.python.org/downloads/release/python-3120/)

âœ… **Important**: During installation, check the box **â€œAdd Python to PATHâ€**

---

### 2. ğŸ§  Install Ollama (Local LLM Runtime)

Ollama allows you to run large language models (LLMs) locally on your machine.

#### ğŸ”§ Windows Installation

1. Download and install Ollama:  
   ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

2. Verify the installation in your terminal:

    ```bash
    ollama --version
    ```

3. Pull the required model for feasibility classification:

    ```bash
    ollama pull mistral
    ```

    > ğŸ’¡ You can replace `mistral` with any other supported model like `llama3`, `codellama`, etc., depending on your use case.

---

### 3. ğŸ“¦ Install Python Dependencies

Install the required packages using `pip`:

```bash
python -m pip install -r requirements.txt

ğŸŒ Launch the Dashboard
Start the Streamlit dashboard with:

streamlit run app.py
You can run this in:

âœ… VS Code Terminal

âœ… Command Prompt / PowerShell

The dashboard will open automatically in your default web browser upload your Test cases excel and click analyze button.

ğŸ‘¨â€ğŸ’» Author
Built by:
Devanath Kuna
Senior Test Automation Specialist @ IBM
ğŸ“ Bengaluru, India
